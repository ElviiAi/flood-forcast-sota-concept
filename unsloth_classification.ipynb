{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqM-T1RTzY6C"
      },
      "source": [
        "# Text classification with Unsloth\n",
        "\n",
        "This modified Unsloth notebook trains an LLM on any text classification dataset, where the input is a csv with columns \"text\" and \"label\".\n",
        "\n",
        "### Added features:\n",
        "\n",
        "- Trims the classification head to contain only the number tokens such as \"1\", \"2\" etc, which saves 1 GB of VRAM, allows you to train the head without massive memory usage, and makes the start of the training session more stable.\n",
        "- Only the last token in the sequence contributes to the loss, the model doesn't waste its capacity by trying to predict the input\n",
        "- includes \"group_by_length = True\" which speeds up training significantly for unbalanced sequence lengths\n",
        "- Efficiently evaluates the accuracy on the validation set using batched inference\n",
        "\n",
        "### Update 4th of May 2025:\n",
        "\n",
        "- Added support for more than 2 classes\n",
        "- The classification head is now built back up to the original size after training, no more errors in external libraries.\n",
        "- Made the batched inference part much faster and cleaner\n",
        "- Changed model to Qwen 3\n",
        "- Improved comments to explain the complicated parts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import os\n",
        "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
        "    !pip install unsloth\n",
        "else:\n",
        "    # Do this only in Colab notebooks! Otherwise use pip install unsloth\n",
        "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft trl==0.15.2 triton cut_cross_entropy unsloth_zoo\n",
        "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
        "    !pip install --no-deps unsloth"
      ],
      "metadata": {
        "id": "3F8_r1rYVLQa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SV6YW0ymVMVy"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ySCkSH_RU7iQ",
        "outputId": "9ced890b-ae72-405a-c395-408697f6a23c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
            "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
          ]
        }
      ],
      "source": [
        "# needed as this function doesn't like it when the lm_head has its size changed\n",
        "from unsloth import tokenizer_utils\n",
        "def do_nothing(*args, **kwargs):\n",
        "    pass\n",
        "tokenizer_utils.fix_untrained_tokens = do_nothing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ZqqnXPSsU7iR",
        "outputId": "c98dec40-9d24-40f0-f059-e2ad81f47a9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 550,
          "referenced_widgets": [
            "bd941a1880d944ca9c0343d9bf460305",
            "1d9e3e21883242c4a8dd115b3af93f77",
            "41fa8402948844bea905212f60241967",
            "b5cea92e4b7946d88a8f5d49bc5b1bfd",
            "05291a74d9ff457bae0d75e0b20a5e0a",
            "d1a28643e1804dfab7299a4fb1ec25f7",
            "7abfd6e0778f4689af2bfe73493381af",
            "8ac0808fb8504ad7afeb02d89df8f4c5",
            "35497a2c303d48a48f6be6da2a43b3d2",
            "d45ea013c5164ad8b8980887cfe5706b",
            "6af6e3b1492c47dfa822cdf16f4ba19d",
            "96c654e7df5e41db81759c6a11ce9aed",
            "3f6267aa93c643fda2bfc6c0c68bf4cf",
            "b3556638f3b144178f26a972d67c75a7",
            "d971da167e7942fd8f9532f67bbc7008",
            "344498a5b8124b76982ad80c108ddeed",
            "05e7fa248ac84b8ab4f003f27d198eef",
            "943e9425e3f545eea314758d5b1adbe7",
            "6ef247fa840a43d7ae437113f9cd94da",
            "a2f9017b3559411195cbfe1583c17beb",
            "2e1ffe6f27944e7a9e3e3e004e00c720",
            "62d59585f5b34f06a14228b227481123",
            "98a20b418076433abf0e2f91ecb036ff",
            "df65deadf56e4031aa59edca88d6c22e",
            "ec6e6ee440d14390aefce7436c57b60f",
            "99ae4a4a305d4436aa3e667bcbc50924",
            "fe057e9c358c4f7daaef7081b90b0e3a",
            "5693850d8e024d648604993e8a4cc38f",
            "0d9aac1d6e6645c791f40e04bc3f1682",
            "3e75445db587418290f1f34e81d76ffe",
            "5660a25024e84db7821461c606e51c8f",
            "261a541f9f034169b5e80b0d7e29f882",
            "377d3d06364d47ca9de1c259829ffb30",
            "be2f022339544d049ee45e0bd28f08f3",
            "e3a2e41e11104bffac8653538971fede",
            "d13ca918031a469391d6cbb8129011ce",
            "e5157af1b6634391b826490fe120ac54",
            "991c79ab5a3642e897de10472b4b80f1",
            "f12101fdfe7242b4b18f99027c7bbd5a",
            "871d49c5745e492289c0032b5aa43f0a",
            "48aa3ea658854dfc96f039b6bc761c0d",
            "5c9a327c270641958c7259bd6e5cd5fa",
            "8a93a02fba0b4be58d29705af7828996",
            "f941c6f9337343d3a1477330c2397e66",
            "e35fa132e04e42ad9d1cf610671d48a4",
            "4ee2411cbb8545c39c4a8e8c6d680afb",
            "a8ac7f2189334e2887a20481ce4ba838",
            "3706816f8aa947558195d449a96ed3b6",
            "64503a098b5847ce9239fc95b7290457",
            "0151d3a1137244cc8214dcc1a31197c7",
            "20357d76f19d408981ee1eee6d91b3ef",
            "8a96312f4b794b11b68c2782b15c02aa",
            "43f23c3c9420421ba740864a732d16fa",
            "9442cc8b7d5642cfb7aeecb086311c5f",
            "1cb7e6e1417f407f827aa6a402bae2b4",
            "3472f3f059db4861a729c3b59ed181b5",
            "1da168a98edc451e8444902a8249e39d",
            "a468415cd9904e358b58dec346cdcabf",
            "f2e2a5cf73a4448297e72e2922a14606",
            "04c65095b4784fc0b4419463947e6173",
            "ce95e616df0d4578a190b2667b2a35ba",
            "a612175a596745dcb5b6658663535b35",
            "537feaf2ddac41debadad05d137f0d90",
            "f125f82911f74f9d8c4937fea2ec7a11",
            "f0d43cb281a34d77a3753b2b7b02ea3e",
            "971c54bb468e4fa481e101138df743b3",
            "beb696dcdc0741f4a8e29f22697f27db",
            "9df8d16cc3764c0da6e337bd4838decf",
            "2998de56d6f74669a04f1faa807ff04c",
            "8c152c90faee441e9083554e22582663",
            "25e82d2ab99f47c19b0471dc6361c636",
            "568f0e578d93455e9b3a1fea00ece58c",
            "8220f8b732d3486fb265e75916c2d4bc",
            "a964e7558d634297a46cfcf57455729c",
            "c4ab5a8dfe3a439bb7cebb27195180cd",
            "cb77d89aacce49099c894127375e8727",
            "0dc1b7edbc9f43e1817a79c10677a3d4",
            "bf0a21cad9d14cbab37e6275dd01c75f",
            "13ac964dfa444e76beec0d7c77583daa",
            "23f393aa67c948ebbcdfd598263721d4",
            "f6143fd3c7ed4a37b76387cb87bc63a9",
            "408930d8a0de4ad597ce90ec63235d3a",
            "7309a8ffd5514940883ad0cf0163311b",
            "a3b38e1175e54291807585d19f9fd5cb",
            "af6f02a5c41646748e5f596cb8b414b4",
            "83784590d47944a29af3fabdf30873b8",
            "fbab9be28a0f4a5fbb02ba7386d351fa",
            "4d95414589f34ed6ae45bfb5e7941ff2",
            "355d6552d1df461d991c72de64686fbe",
            "869b2673e6cf42a4bfcbf3fc1ec028b7",
            "3c8858012bbc4b08bd31957f6d769f6e",
            "03181185ffef47b0bd90d0a1afa828d8",
            "a77a601e4d1c450eac98ddb493f52941",
            "a77d352b03154b3e8e882e899e1e2bb0",
            "0d7babc973be4dde977099c81bb2c828",
            "686511d44ed44fc6942981908126c6f6",
            "df2ab9578ba641b9b4bab722ef744b20",
            "a3ecaa70605a4f9f8c6502df541a88a2",
            "4c388f3181c24e12add63b19e50043ca",
            "e64b1ec7811b403499a205cb5aa60c79",
            "4d41043fc7b04ebba405f627cd02a1b4",
            "d832a52048b9402585f1c38e7ccc29bb",
            "9caec7a64b174b4a80883dfb4466914d",
            "91193079c5654c089f1b38734759d9cd",
            "cb294682a59943c0afb85e66e52085b6",
            "51c6b03a6eb848beafb47fa7c65fe1b0",
            "7746fc0abb8e4a9496ec169d81060fd2",
            "650096000ce941cb904dea66e4cbea22",
            "512cb2e673854bcc889a8df218a34b60",
            "cfeab7eb078f48e392546956a0643c2a",
            "069a6bccef88492aafb5e87913b36f1b",
            "7203f6b82e5e4223a939739a594daa25",
            "8769623a027440579416de6a341a4960",
            "9797cb51d81d4d79b41602a01a333885",
            "079dd283186344b393eb708c9f966204",
            "689f09f92cf446b896608cac44290b2c",
            "ebcddabc69484b10b8ad0b9937dcb8fd",
            "a598c06b69734dcb983b7211312978e8",
            "70e4130ffd274e028fd0df207edaaef7",
            "1e2b4bbba17646a2803e666fb38d83cd",
            "5e1876d2fa7d4443987f38a701588e81"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major: 7, Minor: 5\n",
            "==((====))==  Unsloth 2025.5.7: Fast Gemma3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/4.56G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bd941a1880d944ca9c0343d9bf460305"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/210 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "96c654e7df5e41db81759c6a11ce9aed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "processor_config.json:   0%|          | 0.00/70.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98a20b418076433abf0e2f91ecb036ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.json:   0%|          | 0.00/1.61k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "be2f022339544d049ee45e0bd28f08f3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "chat_template.jinja:   0%|          | 0.00/1.53k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e35fa132e04e42ad9d1cf610671d48a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3472f3f059db4861a729c3b59ed181b5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.16M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "beb696dcdc0741f4a8e29f22697f27db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.69M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bf0a21cad9d14cbab37e6275dd01c75f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/33.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "355d6552d1df461d991c72de64686fbe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "added_tokens.json:   0%|          | 0.00/35.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e64b1ec7811b403499a205cb5aa60c79"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/670 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "069a6bccef88492aafb5e87913b36f1b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
        "from datasets import load_dataset\n",
        "import datasets\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from typing import Tuple\n",
        "import warnings\n",
        "from typing import Any, Dict, List, Union\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_CLASSES = 3 # number of classes in the csv\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\n",
        "model_name = \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\";load_in_4bit = True\n",
        "# model_name = \"Qwen3-4B-Base\";load_in_4bit = False\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,load_in_4bit = load_in_4bit,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXd9bTZd1aaL"
      },
      "source": [
        "We now trim the classification head so the model can only say numbers 0-NUM_CLASSES and no other words. (We don't use 0 here but keeping it makes everything simpler)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "38t07djqU7iR",
        "outputId": "16597cbe-f9b9-4313-f568-a23dcdf260fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Major: 7, Minor: 5\n",
            "==((====))==  Unsloth 2025.5.7: Fast Gemma3 patching. Transformers: 4.51.3.\n",
            "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
            "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
            "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
            " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
            "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
            "Unsloth: Using float16 precision for gemma3 won't work! Using float32.\n",
            "torch.Size([4, 2560])\n",
            "torch.Size([262208, 2560])\n",
            "{236771: 0, 236770: 1, 236778: 2, 236800: 3}\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "print(f\"Major: {major_version}, Minor: {minor_version}\")\n",
        "from datasets import load_dataset\n",
        "import datasets\n",
        "from trl import SFTTrainer\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from unsloth import FastLanguageModel\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments, Trainer, AutoTokenizer # Import AutoTokenizer\n",
        "from typing import Tuple\n",
        "import warnings\n",
        "from typing import Any, Dict, List, Union\n",
        "from transformers import DataCollatorForLanguageModeling\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "NUM_CLASSES = 3 # number of classes in the csv\n",
        "\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "\n",
        "model_name = \"unsloth/gemma-3-4b-it-unsloth-bnb-4bit\";load_in_4bit = True\n",
        "# model_name = \"Qwen3-4B-Base\";load_in_4bit = False\n",
        "\n",
        "# Load the model using FastLanguageModel\n",
        "model, _ = FastLanguageModel.from_pretrained(\n",
        "    model_name = model_name,load_in_4bit = load_in_4bit,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        ")\n",
        "\n",
        "# Explicitly load a text tokenizer using AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "number_token_ids = []\n",
        "for i in range(0, NUM_CLASSES+1):\n",
        "    # Now use the explicitly loaded tokenizer\n",
        "    number_token_ids.append(tokenizer.encode(str(i), add_special_tokens=False)[0])\n",
        "\n",
        "# keep only the number tokens from lm_head\n",
        "# Check if number_token_ids is not empty before proceeding\n",
        "if not number_token_ids:\n",
        "    raise ValueError(\"Failed to encode any number tokens.\")\n",
        "\n",
        "# Access lm_head via the identified path: model.language_model.lm_head\n",
        "if hasattr(model, 'language_model') and hasattr(model.language_model, 'lm_head'):\n",
        "     par = torch.nn.Parameter(model.language_model.lm_head.weight[number_token_ids, :])\n",
        "     old_shape = model.language_model.lm_head.weight.shape\n",
        "     old_size = old_shape[0]\n",
        "     print(par.shape)\n",
        "     print(old_shape)\n",
        "     model.language_model.lm_head.weight = par\n",
        "     # Check for bias and handle it if it exists\n",
        "     if hasattr(model.language_model.lm_head, 'bias') and model.language_model.lm_head.bias is not None:\n",
        "         par_bias = torch.nn.Parameter(model.language_model.lm_head.bias[number_token_ids])\n",
        "         model.language_model.lm_head.bias = par_bias\n",
        "         print(f\"Trimmed bias shape: {par_bias.shape}\")\n",
        "\n",
        "elif hasattr(model, 'lm_head'): # Fallback to direct access if model.language_model.lm_head doesn't exist (less likely now)\n",
        "     par = torch.nn.Parameter(model.lm_head.weight[number_token_ids, :])\n",
        "     old_shape = model.lm_head.weight.shape\n",
        "     old_size = old_shape[0]\n",
        "     print(par.shape)\n",
        "     print(old_shape)\n",
        "     model.lm_head.weight = par\n",
        "      # Check for bias and handle it if it exists\n",
        "     if hasattr(model.lm_head, 'bias') and model.lm_head.bias is not None:\n",
        "         par_bias = torch.nn.Parameter(model.lm_head.bias[number_token_ids])\n",
        "         model.lm_head.bias = par_bias\n",
        "         print(f\"Trimmed bias shape: {par_bias.shape}\")\n",
        "\n",
        "else:\n",
        "    raise AttributeError(\"Could not find 'lm_head' attribute on the model, model.model, or model.language_model.\")\n",
        "\n",
        "\n",
        "reverse_map = {value: idx for idx, value in enumerate(number_token_ids)} # will be used later to convert an idx from the old tokenizer to the new lm_head\n",
        "print(reverse_map)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "def print_module_names(module, prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Recursively prints the names of all submodules in a PyTorch module.\n",
        "    \"\"\"\n",
        "    for name, submodule in module.named_children():\n",
        "        submodule_path = prefix + \".\" + name if prefix else name\n",
        "        print(f\"Module: {submodule_path}, Type: {type(submodule)}\")\n",
        "        # Recursively call for submodules\n",
        "        print_module_names(submodule, submodule_path)\n",
        "\n",
        "# Assuming 'model' is your loaded FastLanguageModel object\n",
        "print(\"Exploring model structure:\")\n",
        "print_module_names(model)\n",
        "\n",
        "# You can also inspect specific parts if you have hunches, e.g.,\n",
        "# if hasattr(model, 'model'):\n",
        "#     print(\"\\nExploring model.model structure:\")\n",
        "#     print_module_names(model.model, prefix=\"model\")\n",
        "\n",
        "# After running this, look for a Linear layer at or near the end of the structure.\n",
        "# Its name might give you a clue about the correct attribute path."
      ],
      "metadata": {
        "id": "xblZLw0ZYVWf",
        "outputId": "1be98052-edc6-485a-a5b1-42a90c97b3bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exploring model structure:\n",
            "Module: vision_tower, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipVisionModel'>\n",
            "Module: vision_tower.vision_model, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipVisionTransformer'>\n",
            "Module: vision_tower.vision_model.embeddings, Type: <class 'unsloth_compiled_module_siglip.SiglipVisionEmbeddings'>\n",
            "Module: vision_tower.vision_model.embeddings.patch_embedding, Type: <class 'torch.nn.modules.conv.Conv2d'>\n",
            "Module: vision_tower.vision_model.embeddings.position_embedding, Type: <class 'torch.nn.modules.sparse.Embedding'>\n",
            "Module: vision_tower.vision_model.encoder, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoder'>\n",
            "Module: vision_tower.vision_model.encoder.layers, Type: <class 'torch.nn.modules.container.ModuleList'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.0.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.1.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.2.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.3.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.4.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.5.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.6.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.7.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.8.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.9.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.10.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.11.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.12.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.13.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.14.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.15.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.16.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.17.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.18.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.19.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.20.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.21.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.22.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.23.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.24.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.25.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26, Type: <class 'transformers.models.siglip.modeling_siglip.SiglipEncoderLayer'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.layer_norm1, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.self_attn, Type: <class 'unsloth_compiled_module_siglip.SiglipAttention'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.self_attn.out_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.layer_norm2, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.mlp, Type: <class 'unsloth_compiled_module_siglip.SiglipMLP'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.mlp.activation_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.mlp.fc1, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.encoder.layers.26.mlp.fc2, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: vision_tower.vision_model.post_layernorm, Type: <class 'torch.nn.modules.normalization.LayerNorm'>\n",
            "Module: multi_modal_projector, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MultiModalProjector'>\n",
            "Module: multi_modal_projector.mm_soft_emb_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: multi_modal_projector.avg_pool, Type: <class 'torch.nn.modules.pooling.AvgPool2d'>\n",
            "Module: language_model, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3ForCausalLM'>\n",
            "Module: language_model.model, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3TextModel'>\n",
            "Module: language_model.model.embed_tokens, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3TextScaledWordEmbedding'>\n",
            "Module: language_model.model.layers, Type: <class 'torch.nn.modules.container.ModuleList'>\n",
            "Module: language_model.model.layers.0, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.0.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.0.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.0.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.0.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.0.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.0.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.0.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.0.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.0.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.0.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.0.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.0.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.0.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.0.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.0.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.0.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.1.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.1.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.1.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.1.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.1.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.1.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.1.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.1.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.1.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.1.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.1.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.1.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.2.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.2.self_attn.q_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.self_attn.k_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.self_attn.v_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.self_attn.o_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.2.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.2.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.2.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.2.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.3.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.3.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.3.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.3.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.3.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.3.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.3.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.3.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.3.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.3.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.3.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.3.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.4.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.4.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.4.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.4.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.4.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.4.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.4.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.4.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.4.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.4.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.4.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.4.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.5.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.5.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.5.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.5.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.5.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.5.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.5.mlp.gate_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.5.mlp.up_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.5.mlp.down_proj, Type: <class 'torch.nn.modules.linear.Linear'>\n",
            "Module: language_model.model.layers.5.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.5.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.5.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.6.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.6.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.6.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.6.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.6.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.6.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.7.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.7.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.7.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.7.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.7.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.7.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.8.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.8.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.8.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.8.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.8.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.8.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.9.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.9.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.9.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.9.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.9.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.9.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.10.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.10.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.10.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.10.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.10.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.10.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.11.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.11.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.11.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.11.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.11.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.11.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.12.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.12.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.12.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.12.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.12.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.12.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.13.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.13.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.13.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.13.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.13.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.13.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.14.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.14.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.14.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.14.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.14.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.14.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.15.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.15.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.15.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.15.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.15.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.15.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.16.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.16.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.16.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.16.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.16.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.16.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.17.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.17.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.17.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.17.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.17.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.17.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.18.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.18.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.18.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.18.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.18.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.18.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.19.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.19.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.19.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.19.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.19.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.19.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.20.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.20.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.20.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.20.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.20.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.20.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.21.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.21.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.21.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.21.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.21.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.21.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.22.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.22.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.22.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.22.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.22.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.22.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.23.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.23.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.23.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.23.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.23.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.23.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.24.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.24.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.24.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.24.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.24.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.24.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.25.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.25.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.25.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.25.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.25.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.25.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.26.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.26.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.26.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.26.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.26.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.26.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.27.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.27.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.27.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.27.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.27.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.27.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.28.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.28.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.28.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.28.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.28.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.28.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.29.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.29.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.29.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.29.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.29.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.29.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.30.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.30.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.30.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.30.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.30.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.30.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.31.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.31.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.31.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.31.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.31.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.31.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.32.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.32.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.32.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.32.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.32.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.32.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3DecoderLayer'>\n",
            "Module: language_model.model.layers.33.self_attn, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3Attention'>\n",
            "Module: language_model.model.layers.33.self_attn.q_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.self_attn.k_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.self_attn.v_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.self_attn.o_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.self_attn.q_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33.self_attn.k_norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33.mlp, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3MLP'>\n",
            "Module: language_model.model.layers.33.mlp.gate_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.mlp.up_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.mlp.down_proj, Type: <class 'bitsandbytes.nn.modules.Linear4bit'>\n",
            "Module: language_model.model.layers.33.mlp.act_fn, Type: <class 'transformers.activations.PytorchGELUTanh'>\n",
            "Module: language_model.model.layers.33.input_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33.post_attention_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33.pre_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.layers.33.post_feedforward_layernorm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.norm, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RMSNorm'>\n",
            "Module: language_model.model.rotary_emb, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RotaryEmbedding'>\n",
            "Module: language_model.model.rotary_emb_local, Type: <class 'transformers.models.gemma3.modeling_gemma3.Gemma3RotaryEmbedding'>\n",
            "Module: language_model.lm_head, Type: <class 'torch.nn.modules.linear.Linear'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "r34UhQmxU7iR",
        "outputId": "2afbae4a-6d24-478c-98b9-8ca2ba890efd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/peft/tuners/tuners_utils.py:550: UserWarning: Model with `tie_word_embeddings=True` and the tied_target_modules=['language_model.lm_head'] are part of the adapter. This can lead to complications, for example when merging the adapter or converting your model to formats other than safetensors. See for example https://github.com/huggingface/peft/issues/2018.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unsloth: Making `base_model.model.vision_tower.vision_model` require gradients\n",
            "trainable parameters: 37024768\n"
          ]
        }
      ],
      "source": [
        "from peft import LoftQConfig\n",
        "\n",
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    finetune_vision_layers     = False,\n",
        "    finetune_language_layers   = True,  # Should leave on!\n",
        "    finetune_attention_modules = True,  # Attention good for GRPO\n",
        "    finetune_mlp_modules       = True,  # SHould leave on always!\n",
        "    r = 16,\n",
        "    target_modules = [\n",
        "        \"lm_head\", # can easily be trained because it now has a small size\n",
        "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "        \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    use_gradient_checkpointing = \"unsloth\",\n",
        "    random_state = 3407,\n",
        "    use_rslora = True,  # We support rank stabilized LoRA\n",
        "    # init_lora_weights = 'loftq',\n",
        "    # loftq_config = LoftQConfig(loftq_bits = 4, loftq_iter = 1), # And LoftQ\n",
        ")\n",
        "print(\"trainable parameters:\", sum(p.numel() for p in model.parameters() if p.requires_grad))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n1rwIIzuU7iR"
      },
      "source": [
        "The dataset can be found [here](https://github.com/timothelaborie/text_classification_scripts/blob/main/data/finance_sentiment_multiclass.csv)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "dToEDAVUU7iR",
        "outputId": "d6c3b70f-1141-42fa-b72d-29921ec31427",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 490
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'data/finance_sentiment_multiclass.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-25f1549ea42f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mkaggle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"/kaggle/working\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/kaggle/input/whatever/\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mkaggle\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"data/\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_dir\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"finance_sentiment_multiclass.csv\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# columns are text,label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m42\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data/finance_sentiment_multiclass.csv'"
          ]
        }
      ],
      "source": [
        "kaggle = os.getcwd() == \"/kaggle/working\"\n",
        "input_dir = \"/kaggle/input/whatever/\" if kaggle else \"data/\"\n",
        "data = pd.read_csv(input_dir + \"finance_sentiment_multiclass.csv\") # columns are text,label\n",
        "\n",
        "train_df, val_df = train_test_split(data, test_size=0.1, random_state=42)\n",
        "print(len(train_df))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8v7gsUq1U7iS"
      },
      "outputs": [],
      "source": [
        "token_counts = [len(tokenizer.encode(x)) for x in train_df.text]\n",
        "# plot the token counts\n",
        "a = plt.hist(token_counts, bins=30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LjY75GoYUCB8"
      },
      "outputs": [],
      "source": [
        "prompt = \"\"\"Here is a financial news:\n",
        "{}\n",
        "\n",
        "Classify this news into one of the following:\n",
        "class 1: Bullish\n",
        "class 2: Neutral\n",
        "class 3: Bearish\n",
        "\n",
        "SOLUTION\n",
        "The correct answer is: class {}\"\"\"\n",
        "\n",
        "def formatting_prompts_func(dataset_):\n",
        "    texts = []\n",
        "    for i in range(len(dataset_['text'])):\n",
        "        text_ = dataset_['text'].iloc[i]\n",
        "        label_ = dataset_['label'].iloc[i] # the csv is setup so that the label column corresponds exactly to the 3 classes defined above in the prompt (important)\n",
        "\n",
        "        text = prompt.format(text_, label_)\n",
        "\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "# apply formatting_prompts_func to train_df\n",
        "train_df['text'] = formatting_prompts_func(train_df)\n",
        "train_dataset = datasets.Dataset.from_pandas(train_df,preserve_index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ghilz6-cU7iS"
      },
      "outputs": [],
      "source": [
        "# this custom collator makes it so the model trains only on the last token of the sequence. It also maps from the old tokenizer to the new lm_head indices\n",
        "class DataCollatorForLastTokenLM(DataCollatorForLanguageModeling):\n",
        "    def __init__(\n",
        "        self,\n",
        "        *args,\n",
        "        mlm: bool = False,\n",
        "        ignore_index: int = -100,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, mlm=mlm, **kwargs)\n",
        "        self.ignore_index = ignore_index\n",
        "\n",
        "    def torch_call(self, examples: List[Union[List[int], Any, Dict[str, Any]]]) -> Dict[str, Any]:\n",
        "        batch = super().torch_call(examples)\n",
        "\n",
        "        for i in range(len(examples)):\n",
        "            # Find the last non-padding token\n",
        "            last_token_idx = (batch[\"labels\"][i] != self.ignore_index).nonzero()[-1].item()\n",
        "            # Set all labels to ignore_index except for the last token\n",
        "            batch[\"labels\"][i, :last_token_idx] = self.ignore_index\n",
        "            # If the last token in the text is, for example, \"2\", then this was processed with the old tokenizer into number_token_ids[2]\n",
        "            # But we don't actually want this because number_token_ids[2] could be something like 27, which is now undefined in the new lm_head. So we map it to the new lm_head index.\n",
        "            # if this line gives you a keyerror then increase max_seq_length\n",
        "            batch[\"labels\"][i, last_token_idx] = reverse_map[ batch[\"labels\"][i, last_token_idx].item() ]\n",
        "\n",
        "\n",
        "        return batch\n",
        "collator = DataCollatorForLastTokenLM(tokenizer=tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idAEIeSQ3xdS"
      },
      "source": [
        "<a name=\"Train\"></a>\n",
        "### Train the model\n",
        "Now let's use Huggingface TRL's `SFTTrainer`! More docs here: [TRL SFT docs](https://huggingface.co/docs/trl/sft_trainer). We do 60 steps to speed things up, but you can set `num_train_epochs=1` for a full run, and turn off `max_steps=None`. We also support TRL's `DPOTrainer`!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "95_Nn-89DhsL"
      },
      "outputs": [],
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = train_dataset,\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 1,\n",
        "    packing = False, # not needed because group_by_length is True\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 32,\n",
        "        gradient_accumulation_steps = 1,\n",
        "        warmup_steps = 10,\n",
        "        learning_rate = 1e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"cosine\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "        num_train_epochs = 1,\n",
        "        # report_to = \"wandb\",\n",
        "        report_to = \"none\",\n",
        "        group_by_length = True,\n",
        "    ),\n",
        "    data_collator=collator,\n",
        "    dataset_text_field=\"text\",\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2ejIt2xSNKKp"
      },
      "outputs": [],
      "source": [
        "#@title Show current memory stats\n",
        "gpu_stats = torch.cuda.get_device_properties(0)\n",
        "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
        "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
        "print(f\"{start_gpu_memory} GB of memory reserved.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yqxqAZ7KJ4oL"
      },
      "outputs": [],
      "source": [
        "trainer_stats = trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "pCqnaKmlO1U9"
      },
      "outputs": [],
      "source": [
        "#@title Show final memory and time stats\n",
        "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
        "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
        "used_percentage = round(used_memory         /max_memory*100, 3)\n",
        "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
        "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
        "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
        "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
        "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
        "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
        "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ekOmTR1hSNcr"
      },
      "source": [
        "<a name=\"Inference\"></a>\n",
        "### Inference\n",
        "This part evaluates the model on the val set with batched inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJlfPAnlU7iS"
      },
      "outputs": [],
      "source": [
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8X9C78NU7iS"
      },
      "source": [
        "### remake the old lm_head but with unused tokens having -1000 bias and 0 weights (improves compatibility with libraries like vllm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR9ZogAZU7iT"
      },
      "outputs": [],
      "source": [
        "# Save the current (trimmed) lm_head and bias\n",
        "trimmed_lm_head = model.lm_head.weight.data.clone()\n",
        "trimmed_lm_head_bias = model.lm_head.bias.data.clone() if hasattr(model.lm_head, \"bias\") and model.lm_head.bias is not None else torch.zeros(len(number_token_ids), device=trimmed_lm_head.device)\n",
        "\n",
        "# Create a new lm_head with shape [old_size, hidden_dim]\n",
        "hidden_dim = trimmed_lm_head.shape[1]\n",
        "new_lm_head = torch.full((old_size, hidden_dim), 0, dtype=trimmed_lm_head.dtype, device=trimmed_lm_head.device)\n",
        "new_lm_head_bias = torch.full((old_size,), -1000.0, dtype=trimmed_lm_head_bias.dtype, device=trimmed_lm_head_bias.device)\n",
        "\n",
        "# Fill in the weights and bias for the allowed tokens (number_token_ids)\n",
        "for new_idx, orig_token_id in enumerate(number_token_ids):\n",
        "    new_lm_head[orig_token_id] = trimmed_lm_head[new_idx]\n",
        "    new_lm_head_bias[orig_token_id] = trimmed_lm_head_bias[new_idx]\n",
        "\n",
        "# Update the model's lm_head weight and bias\n",
        "with torch.no_grad():\n",
        "    new_lm_head_module = torch.nn.Linear(hidden_dim, old_size, bias=True, device=model.device)\n",
        "    new_lm_head_module.weight.data.copy_(new_lm_head)\n",
        "    new_lm_head_module.bias.data.copy_(new_lm_head_bias)\n",
        "    model.lm_head.modules_to_save[\"default\"] = new_lm_head_module\n",
        "\n",
        "print(f\"Remade lm_head: shape = {model.lm_head.weight.shape}. Allowed tokens: {number_token_ids}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZhaKl4KnU7iT"
      },
      "source": [
        "# Batched Inference on Validation Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sBnb_1VXU7iT"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Prepare inference prompt\n",
        "inference_prompt_template = prompt.split(\"class {}\")[0] + \"class \"\n",
        "\n",
        "# Sort validation set by length for efficient batching\n",
        "val_df['token_length'] = val_df['text'].apply(lambda x: len(tokenizer.encode(x, add_special_tokens=False)))\n",
        "val_df_sorted = val_df.sort_values(by='token_length').reset_index(drop=True)\n",
        "\n",
        "display = 50\n",
        "batch_size = 16\n",
        "device = model.device\n",
        "correct = 0\n",
        "results = []\n",
        "\n",
        "with torch.inference_mode():\n",
        "    for i in tqdm(range(0, len(val_df_sorted), batch_size), desc=\"Evaluating\"):\n",
        "        batch = val_df_sorted.iloc[i:i+batch_size]\n",
        "        prompts = [inference_prompt_template.format(text) for text in batch['text']]\n",
        "        inputs = tokenizer(prompts, return_tensors=\"pt\", padding=True, truncation=True, max_length=max_seq_length).to(device)\n",
        "        logits = model(**inputs).logits\n",
        "        last_idxs = inputs.attention_mask.sum(1) - 1\n",
        "        last_logits = logits[torch.arange(len(batch)), last_idxs, :]\n",
        "        probs_all = F.softmax(last_logits, dim=-1)\n",
        "        probs = probs_all[:, number_token_ids] # only keep the logits for the number tokens\n",
        "        preds = torch.argmax(probs, dim=-1).cpu().numpy() # looks like [1 1 1 1 3 1 3 1 3 1 1 1 1 2 2 3]\n",
        "\n",
        "        true_labels = batch['label'].tolist()\n",
        "        correct += sum([p == t for p, t in zip(preds, true_labels)])\n",
        "        # Store a few samples for display\n",
        "        for j in range(len(batch)):\n",
        "            results.append({\n",
        "                \"text\": batch['text'].iloc[j][:200],\n",
        "                \"true\": true_labels[j],\n",
        "                \"pred\": preds[j],\n",
        "                \"probs\": probs[j][1:].float().cpu().numpy(), # ignore prob for class 0 and convert from tensor to float\n",
        "                \"ok\": preds[j] == true_labels[j]\n",
        "            })\n",
        "\n",
        "accuracy = 100 * correct / len(val_df_sorted)\n",
        "print(f\"\\nValidation accuracy: {accuracy:.2f}% ({correct}/{len(val_df_sorted)})\")\n",
        "\n",
        "print(\"\\n--- Random samples ---\")\n",
        "for s in random.sample(results, min(display, len(results))):\n",
        "    print(f\"\\nText: {s['text']}\")\n",
        "    print(f\"True: {s['true']}  Pred: {s['pred']} {'âœ…' if s['ok'] else 'âŒ'}\")\n",
        "    print(\"Probs:\", \", \".join([f\"{k}: {v:.3f}\" for k, v in enumerate(s['probs'], start=1)]))\n",
        "\n",
        "# Clean up\n",
        "if 'token_length' in val_df:\n",
        "    del val_df['token_length']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "un2cBTYWU7iT"
      },
      "outputs": [],
      "source": [
        "# stop running all cells\n",
        "1/0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERTTL32fU7iT"
      },
      "source": [
        "Now if you closed the notebook kernel and want to reload the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ne3PafLSU7iT"
      },
      "outputs": [],
      "source": [
        "# load the model\n",
        "from unsloth import FastLanguageModel\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    \"lora_model_Qwen3-4B-Base\",\n",
        "    load_in_4bit = False,\n",
        "    max_seq_length = 2048,\n",
        "    dtype = None,\n",
        ")\n",
        "print(\"Model loaded successfully.\")\n",
        "\n",
        "FastLanguageModel.for_inference(model)\n",
        "\n",
        "prompt = \"\"\"Here is a financial news:\n",
        "For the global oil market, the coronavirus epidemic couldn't have hit a worse place\n",
        "\n",
        "Classify this news into one of the following:\n",
        "class 1: Bullish\n",
        "class 2: Neutral\n",
        "class 3: Bearish\n",
        "\n",
        "SOLUTION\n",
        "The correct answer is: class \"\"\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "outputs = model.generate(**inputs, max_new_tokens=1, use_cache=True)\n",
        "decoded = tokenizer.batch_decode(outputs)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f422JgM9sdVT"
      },
      "source": [
        "### Saving to float16 for VLLM\n",
        "\n",
        "We also support saving to `float16` directly. Select `merged_16bit` for float16 or `merged_4bit` for int4. We also allow `lora` adapters as a fallback. Use `push_to_hub_merged` to upload to your Hugging Face account! You can go to https://huggingface.co/settings/tokens for your personal tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHjt_SMYsd3P"
      },
      "outputs": [],
      "source": [
        "# Merge to 16bit\n",
        "if False: model.save_pretrained_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_16bit\", token = \"\")\n",
        "\n",
        "# Merge to 4bit\n",
        "if False: model.save_pretrained_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"merged_4bit\", token = \"\")\n",
        "\n",
        "# Just LoRA adapters\n",
        "if False: model.save_pretrained_merged(\"model\", tokenizer, save_method = \"lora\",)\n",
        "if False: model.push_to_hub_merged(\"hf/model\", tokenizer, save_method = \"lora\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCv4vXHd61i7"
      },
      "source": [
        "### GGUF / llama.cpp Conversion\n",
        "To save to `GGUF` / `llama.cpp`, we support it natively now! We clone `llama.cpp` and we default save it to `q8_0`. We allow all methods like `q4_k_m`. Use `save_pretrained_gguf` for local saving and `push_to_hub_gguf` for uploading to HF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqfebeAdT073"
      },
      "outputs": [],
      "source": [
        "# Save to 8bit Q8_0\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer,)\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, token = \"\")\n",
        "\n",
        "# Save to 16bit GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"f16\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"f16\", token = \"\")\n",
        "\n",
        "# Save to q4_k_m GGUF\n",
        "if False: model.save_pretrained_gguf(\"model\", tokenizer, quantization_method = \"q4_k_m\")\n",
        "if False: model.push_to_hub_gguf(\"hf/model\", tokenizer, quantization_method = \"q4_k_m\", token = \"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDp0zNpwe6U_"
      },
      "source": [
        "Now, use the `model-unsloth.gguf` file or `model-unsloth-Q4_K_M.gguf` file in `llama.cpp` or a UI based system like `GPT4All`. You can install GPT4All by going [here](https://gpt4all.io/index.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zt9CHJqO6p30"
      },
      "source": [
        "And we're done! If you have any questions on Unsloth, we have a [Discord](https://discord.gg/u54VK8m8tk) channel! If you find any bugs or want to keep updated with the latest LLM stuff, or need help, join projects etc, feel free to join our Discord!\n",
        "\n",
        "Some other links:\n",
        "1. Zephyr DPO 2x faster [free Colab](https://colab.research.google.com/drive/15vttTpzzVXv_tJwEk-hIcQ0S9FcEWvwP?usp=sharing)\n",
        "2. Llama 7b 2x faster [free Colab](https://colab.research.google.com/drive/1lBzz5KeZJKXjvivbYvmGarix9Ao6Wxe5?usp=sharing)\n",
        "3. TinyLlama 4x faster full Alpaca 52K in 1 hour [free Colab](https://colab.research.google.com/drive/1AZghoNBQaMDgWJpi4RbffGM1h6raLUj9?usp=sharing)\n",
        "4. CodeLlama 34b 2x faster [A100 on Colab](https://colab.research.google.com/drive/1y7A0AxE3y8gdj4AVkl2aZX47Xu3P1wJT?usp=sharing)\n",
        "5. Llama 7b [free Kaggle](https://www.kaggle.com/danielhanchen/unsloth-alpaca-t4-ddp)\n",
        "6. We also did a [blog](https://huggingface.co/blog/unsloth-trl) with ðŸ¤— HuggingFace, and we're in the TRL [docs](https://huggingface.co/docs/trl/main/en/sft_trainer#accelerate-fine-tuning-2x-using-unsloth)!\n",
        "\n",
        "<div class=\"align-center\">\n",
        "  <a href=\"https://github.com/unslothai/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/unsloth%20new%20logo.png\" width=\"115\"></a>\n",
        "  <a href=\"https://discord.gg/u54VK8m8tk\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Discord.png\" width=\"145\"></a>\n",
        "  <a href=\"https://ko-fi.com/unsloth\"><img src=\"https://github.com/unslothai/unsloth/raw/main/images/Kofi button.png\" width=\"145\"></a></a> Support our work if you can! Thanks!\n",
        "</div>"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 5081962,
          "sourceId": 8512897,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bd941a1880d944ca9c0343d9bf460305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d9e3e21883242c4a8dd115b3af93f77",
              "IPY_MODEL_41fa8402948844bea905212f60241967",
              "IPY_MODEL_b5cea92e4b7946d88a8f5d49bc5b1bfd"
            ],
            "layout": "IPY_MODEL_05291a74d9ff457bae0d75e0b20a5e0a"
          }
        },
        "1d9e3e21883242c4a8dd115b3af93f77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1a28643e1804dfab7299a4fb1ec25f7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_7abfd6e0778f4689af2bfe73493381af",
            "value": "model.safetensors:â€‡100%"
          }
        },
        "41fa8402948844bea905212f60241967": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac0808fb8504ad7afeb02d89df8f4c5",
            "max": 4562294331,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_35497a2c303d48a48f6be6da2a43b3d2",
            "value": 4562293896
          }
        },
        "b5cea92e4b7946d88a8f5d49bc5b1bfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d45ea013c5164ad8b8980887cfe5706b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_6af6e3b1492c47dfa822cdf16f4ba19d",
            "value": "â€‡4.56G/4.56Gâ€‡[00:33&lt;00:00,â€‡356MB/s]"
          }
        },
        "05291a74d9ff457bae0d75e0b20a5e0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1a28643e1804dfab7299a4fb1ec25f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7abfd6e0778f4689af2bfe73493381af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8ac0808fb8504ad7afeb02d89df8f4c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35497a2c303d48a48f6be6da2a43b3d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d45ea013c5164ad8b8980887cfe5706b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6af6e3b1492c47dfa822cdf16f4ba19d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96c654e7df5e41db81759c6a11ce9aed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3f6267aa93c643fda2bfc6c0c68bf4cf",
              "IPY_MODEL_b3556638f3b144178f26a972d67c75a7",
              "IPY_MODEL_d971da167e7942fd8f9532f67bbc7008"
            ],
            "layout": "IPY_MODEL_344498a5b8124b76982ad80c108ddeed"
          }
        },
        "3f6267aa93c643fda2bfc6c0c68bf4cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05e7fa248ac84b8ab4f003f27d198eef",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_943e9425e3f545eea314758d5b1adbe7",
            "value": "generation_config.json:â€‡100%"
          }
        },
        "b3556638f3b144178f26a972d67c75a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ef247fa840a43d7ae437113f9cd94da",
            "max": 210,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a2f9017b3559411195cbfe1583c17beb",
            "value": 210
          }
        },
        "d971da167e7942fd8f9532f67bbc7008": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e1ffe6f27944e7a9e3e3e004e00c720",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_62d59585f5b34f06a14228b227481123",
            "value": "â€‡210/210â€‡[00:00&lt;00:00,â€‡21.8kB/s]"
          }
        },
        "344498a5b8124b76982ad80c108ddeed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05e7fa248ac84b8ab4f003f27d198eef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "943e9425e3f545eea314758d5b1adbe7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ef247fa840a43d7ae437113f9cd94da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a2f9017b3559411195cbfe1583c17beb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e1ffe6f27944e7a9e3e3e004e00c720": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d59585f5b34f06a14228b227481123": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98a20b418076433abf0e2f91ecb036ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_df65deadf56e4031aa59edca88d6c22e",
              "IPY_MODEL_ec6e6ee440d14390aefce7436c57b60f",
              "IPY_MODEL_99ae4a4a305d4436aa3e667bcbc50924"
            ],
            "layout": "IPY_MODEL_fe057e9c358c4f7daaef7081b90b0e3a"
          }
        },
        "df65deadf56e4031aa59edca88d6c22e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5693850d8e024d648604993e8a4cc38f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0d9aac1d6e6645c791f40e04bc3f1682",
            "value": "processor_config.json:â€‡100%"
          }
        },
        "ec6e6ee440d14390aefce7436c57b60f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e75445db587418290f1f34e81d76ffe",
            "max": 70,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5660a25024e84db7821461c606e51c8f",
            "value": 70
          }
        },
        "99ae4a4a305d4436aa3e667bcbc50924": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_261a541f9f034169b5e80b0d7e29f882",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_377d3d06364d47ca9de1c259829ffb30",
            "value": "â€‡70.0/70.0â€‡[00:00&lt;00:00,â€‡4.49kB/s]"
          }
        },
        "fe057e9c358c4f7daaef7081b90b0e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5693850d8e024d648604993e8a4cc38f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d9aac1d6e6645c791f40e04bc3f1682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e75445db587418290f1f34e81d76ffe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5660a25024e84db7821461c606e51c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "261a541f9f034169b5e80b0d7e29f882": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "377d3d06364d47ca9de1c259829ffb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "be2f022339544d049ee45e0bd28f08f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e3a2e41e11104bffac8653538971fede",
              "IPY_MODEL_d13ca918031a469391d6cbb8129011ce",
              "IPY_MODEL_e5157af1b6634391b826490fe120ac54"
            ],
            "layout": "IPY_MODEL_991c79ab5a3642e897de10472b4b80f1"
          }
        },
        "e3a2e41e11104bffac8653538971fede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12101fdfe7242b4b18f99027c7bbd5a",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_871d49c5745e492289c0032b5aa43f0a",
            "value": "chat_template.json:â€‡100%"
          }
        },
        "d13ca918031a469391d6cbb8129011ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_48aa3ea658854dfc96f039b6bc761c0d",
            "max": 1615,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5c9a327c270641958c7259bd6e5cd5fa",
            "value": 1615
          }
        },
        "e5157af1b6634391b826490fe120ac54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a93a02fba0b4be58d29705af7828996",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_f941c6f9337343d3a1477330c2397e66",
            "value": "â€‡1.61k/1.61kâ€‡[00:00&lt;00:00,â€‡189kB/s]"
          }
        },
        "991c79ab5a3642e897de10472b4b80f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f12101fdfe7242b4b18f99027c7bbd5a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "871d49c5745e492289c0032b5aa43f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48aa3ea658854dfc96f039b6bc761c0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9a327c270641958c7259bd6e5cd5fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a93a02fba0b4be58d29705af7828996": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f941c6f9337343d3a1477330c2397e66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e35fa132e04e42ad9d1cf610671d48a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4ee2411cbb8545c39c4a8e8c6d680afb",
              "IPY_MODEL_a8ac7f2189334e2887a20481ce4ba838",
              "IPY_MODEL_3706816f8aa947558195d449a96ed3b6"
            ],
            "layout": "IPY_MODEL_64503a098b5847ce9239fc95b7290457"
          }
        },
        "4ee2411cbb8545c39c4a8e8c6d680afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0151d3a1137244cc8214dcc1a31197c7",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_20357d76f19d408981ee1eee6d91b3ef",
            "value": "chat_template.jinja:â€‡100%"
          }
        },
        "a8ac7f2189334e2887a20481ce4ba838": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a96312f4b794b11b68c2782b15c02aa",
            "max": 1532,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_43f23c3c9420421ba740864a732d16fa",
            "value": 1532
          }
        },
        "3706816f8aa947558195d449a96ed3b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9442cc8b7d5642cfb7aeecb086311c5f",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_1cb7e6e1417f407f827aa6a402bae2b4",
            "value": "â€‡1.53k/1.53kâ€‡[00:00&lt;00:00,â€‡152kB/s]"
          }
        },
        "64503a098b5847ce9239fc95b7290457": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0151d3a1137244cc8214dcc1a31197c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20357d76f19d408981ee1eee6d91b3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a96312f4b794b11b68c2782b15c02aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43f23c3c9420421ba740864a732d16fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9442cc8b7d5642cfb7aeecb086311c5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1cb7e6e1417f407f827aa6a402bae2b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3472f3f059db4861a729c3b59ed181b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1da168a98edc451e8444902a8249e39d",
              "IPY_MODEL_a468415cd9904e358b58dec346cdcabf",
              "IPY_MODEL_f2e2a5cf73a4448297e72e2922a14606"
            ],
            "layout": "IPY_MODEL_04c65095b4784fc0b4419463947e6173"
          }
        },
        "1da168a98edc451e8444902a8249e39d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce95e616df0d4578a190b2667b2a35ba",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a612175a596745dcb5b6658663535b35",
            "value": "preprocessor_config.json:â€‡100%"
          }
        },
        "a468415cd9904e358b58dec346cdcabf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_537feaf2ddac41debadad05d137f0d90",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f125f82911f74f9d8c4937fea2ec7a11",
            "value": 570
          }
        },
        "f2e2a5cf73a4448297e72e2922a14606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f0d43cb281a34d77a3753b2b7b02ea3e",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_971c54bb468e4fa481e101138df743b3",
            "value": "â€‡570/570â€‡[00:00&lt;00:00,â€‡43.6kB/s]"
          }
        },
        "04c65095b4784fc0b4419463947e6173": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce95e616df0d4578a190b2667b2a35ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a612175a596745dcb5b6658663535b35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "537feaf2ddac41debadad05d137f0d90": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f125f82911f74f9d8c4937fea2ec7a11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f0d43cb281a34d77a3753b2b7b02ea3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "971c54bb468e4fa481e101138df743b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "beb696dcdc0741f4a8e29f22697f27db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9df8d16cc3764c0da6e337bd4838decf",
              "IPY_MODEL_2998de56d6f74669a04f1faa807ff04c",
              "IPY_MODEL_8c152c90faee441e9083554e22582663"
            ],
            "layout": "IPY_MODEL_25e82d2ab99f47c19b0471dc6361c636"
          }
        },
        "9df8d16cc3764c0da6e337bd4838decf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_568f0e578d93455e9b3a1fea00ece58c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_8220f8b732d3486fb265e75916c2d4bc",
            "value": "tokenizer_config.json:â€‡100%"
          }
        },
        "2998de56d6f74669a04f1faa807ff04c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a964e7558d634297a46cfcf57455729c",
            "max": 1158492,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c4ab5a8dfe3a439bb7cebb27195180cd",
            "value": 1158492
          }
        },
        "8c152c90faee441e9083554e22582663": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb77d89aacce49099c894127375e8727",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0dc1b7edbc9f43e1817a79c10677a3d4",
            "value": "â€‡1.16M/1.16Mâ€‡[00:00&lt;00:00,â€‡7.98MB/s]"
          }
        },
        "25e82d2ab99f47c19b0471dc6361c636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "568f0e578d93455e9b3a1fea00ece58c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8220f8b732d3486fb265e75916c2d4bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a964e7558d634297a46cfcf57455729c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c4ab5a8dfe3a439bb7cebb27195180cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cb77d89aacce49099c894127375e8727": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0dc1b7edbc9f43e1817a79c10677a3d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf0a21cad9d14cbab37e6275dd01c75f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_13ac964dfa444e76beec0d7c77583daa",
              "IPY_MODEL_23f393aa67c948ebbcdfd598263721d4",
              "IPY_MODEL_f6143fd3c7ed4a37b76387cb87bc63a9"
            ],
            "layout": "IPY_MODEL_408930d8a0de4ad597ce90ec63235d3a"
          }
        },
        "13ac964dfa444e76beec0d7c77583daa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7309a8ffd5514940883ad0cf0163311b",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a3b38e1175e54291807585d19f9fd5cb",
            "value": "tokenizer.model:â€‡100%"
          }
        },
        "23f393aa67c948ebbcdfd598263721d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af6f02a5c41646748e5f596cb8b414b4",
            "max": 4689074,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83784590d47944a29af3fabdf30873b8",
            "value": 4689074
          }
        },
        "f6143fd3c7ed4a37b76387cb87bc63a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbab9be28a0f4a5fbb02ba7386d351fa",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4d95414589f34ed6ae45bfb5e7941ff2",
            "value": "â€‡4.69M/4.69Mâ€‡[00:00&lt;00:00,â€‡19.3MB/s]"
          }
        },
        "408930d8a0de4ad597ce90ec63235d3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7309a8ffd5514940883ad0cf0163311b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3b38e1175e54291807585d19f9fd5cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af6f02a5c41646748e5f596cb8b414b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83784590d47944a29af3fabdf30873b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fbab9be28a0f4a5fbb02ba7386d351fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d95414589f34ed6ae45bfb5e7941ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "355d6552d1df461d991c72de64686fbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_869b2673e6cf42a4bfcbf3fc1ec028b7",
              "IPY_MODEL_3c8858012bbc4b08bd31957f6d769f6e",
              "IPY_MODEL_03181185ffef47b0bd90d0a1afa828d8"
            ],
            "layout": "IPY_MODEL_a77a601e4d1c450eac98ddb493f52941"
          }
        },
        "869b2673e6cf42a4bfcbf3fc1ec028b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a77d352b03154b3e8e882e899e1e2bb0",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_0d7babc973be4dde977099c81bb2c828",
            "value": "tokenizer.json:â€‡100%"
          }
        },
        "3c8858012bbc4b08bd31957f6d769f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_686511d44ed44fc6942981908126c6f6",
            "max": 33384568,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_df2ab9578ba641b9b4bab722ef744b20",
            "value": 33384568
          }
        },
        "03181185ffef47b0bd90d0a1afa828d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a3ecaa70605a4f9f8c6502df541a88a2",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_4c388f3181c24e12add63b19e50043ca",
            "value": "â€‡33.4M/33.4Mâ€‡[00:00&lt;00:00,â€‡141MB/s]"
          }
        },
        "a77a601e4d1c450eac98ddb493f52941": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a77d352b03154b3e8e882e899e1e2bb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d7babc973be4dde977099c81bb2c828": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "686511d44ed44fc6942981908126c6f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df2ab9578ba641b9b4bab722ef744b20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a3ecaa70605a4f9f8c6502df541a88a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c388f3181c24e12add63b19e50043ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e64b1ec7811b403499a205cb5aa60c79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4d41043fc7b04ebba405f627cd02a1b4",
              "IPY_MODEL_d832a52048b9402585f1c38e7ccc29bb",
              "IPY_MODEL_9caec7a64b174b4a80883dfb4466914d"
            ],
            "layout": "IPY_MODEL_91193079c5654c089f1b38734759d9cd"
          }
        },
        "4d41043fc7b04ebba405f627cd02a1b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb294682a59943c0afb85e66e52085b6",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_51c6b03a6eb848beafb47fa7c65fe1b0",
            "value": "added_tokens.json:â€‡100%"
          }
        },
        "d832a52048b9402585f1c38e7ccc29bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7746fc0abb8e4a9496ec169d81060fd2",
            "max": 35,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_650096000ce941cb904dea66e4cbea22",
            "value": 35
          }
        },
        "9caec7a64b174b4a80883dfb4466914d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_512cb2e673854bcc889a8df218a34b60",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_cfeab7eb078f48e392546956a0643c2a",
            "value": "â€‡35.0/35.0â€‡[00:00&lt;00:00,â€‡2.66kB/s]"
          }
        },
        "91193079c5654c089f1b38734759d9cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb294682a59943c0afb85e66e52085b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "51c6b03a6eb848beafb47fa7c65fe1b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7746fc0abb8e4a9496ec169d81060fd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "650096000ce941cb904dea66e4cbea22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "512cb2e673854bcc889a8df218a34b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cfeab7eb078f48e392546956a0643c2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "069a6bccef88492aafb5e87913b36f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7203f6b82e5e4223a939739a594daa25",
              "IPY_MODEL_8769623a027440579416de6a341a4960",
              "IPY_MODEL_9797cb51d81d4d79b41602a01a333885"
            ],
            "layout": "IPY_MODEL_079dd283186344b393eb708c9f966204"
          }
        },
        "7203f6b82e5e4223a939739a594daa25": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_689f09f92cf446b896608cac44290b2c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ebcddabc69484b10b8ad0b9937dcb8fd",
            "value": "special_tokens_map.json:â€‡100%"
          }
        },
        "8769623a027440579416de6a341a4960": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a598c06b69734dcb983b7211312978e8",
            "max": 670,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_70e4130ffd274e028fd0df207edaaef7",
            "value": 670
          }
        },
        "9797cb51d81d4d79b41602a01a333885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e2b4bbba17646a2803e666fb38d83cd",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_5e1876d2fa7d4443987f38a701588e81",
            "value": "â€‡670/670â€‡[00:00&lt;00:00,â€‡75.0kB/s]"
          }
        },
        "079dd283186344b393eb708c9f966204": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "689f09f92cf446b896608cac44290b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebcddabc69484b10b8ad0b9937dcb8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a598c06b69734dcb983b7211312978e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "70e4130ffd274e028fd0df207edaaef7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1e2b4bbba17646a2803e666fb38d83cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5e1876d2fa7d4443987f38a701588e81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}